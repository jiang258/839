{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(\"Table_A.csv\")\n",
    "dfb = pd.read_csv(\"Table_B.csv\")\n",
    "dfc = pd.read_csv(\"candidate.csv\")\n",
    "dfp = pd.read_csv(\"prediction_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transtime(x):\n",
    "    if pd.isnull(x[\"Year\"]) == False:\n",
    "        return int(x[\"Year\"][-2:])\n",
    "    else: \n",
    "        return x[\"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = dfa.apply(transtime,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa[\"Year0\"]  = Year\n",
    "dfa = dfa.drop(\"Year\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transtime1(x):\n",
    "    if pd.isnull(x[\"Year\"]) == False:\n",
    "        return x[\"Year\"]%100\n",
    "    else:\n",
    "        return x[\"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year1 = dfb.apply(transtime1,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb[\"Year1\"] = Year1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = dfb.drop(\"Year\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.DataFrame(dfc[\"A_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = pd.DataFrame(dfc[\"B_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df11, dfa, how='left', left_on=\"A_id\",right_on = \"_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df22, dfb, how='left', left_on=\"B_id\",right_on = \"_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat([df3,df4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dif(x):\n",
    "    return abs((x[\"Year1\"] - x[\"Year0\"]))\n",
    "\n",
    "Yeardiff = dff.apply(dif,axis = 1)\n",
    "dff[\"dif\"] = Yeardiff\n",
    "dff_final = dff[dff[\"dif\"] <= 2]\n",
    "## blocking with the difference of release time doesn't 2 years\n",
    "## dff_final is the reduced dataset that contains all the information of two tables, not the reduced candidate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = dff_final.sample(50)## This is the sample from new blocking, where the final density is exactly 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = dff_final.sample(400)## This is the 400 sample, the density in the end is 0.265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy import sqrt\n",
    "\n",
    "delta = .05\n",
    "Z = norm.ppf(1 - (delta / 2))\n",
    "\n",
    "def estimate_PR(labeled_pairs, reduced_cands, predicted_matches):\n",
    "    '''\n",
    "    labeled_pairs - a pandas dataframe with schema id1,id2,label\n",
    "                    Note label needs to be Boolean\n",
    "\n",
    "    reduced_cands - a pandas dataframe with schema id1,id2\n",
    "    predicted_matches - a pandas dataframe with schema id1,id2\n",
    "    \n",
    "    return:\n",
    "        ( (recall lower bound, recall upper bound), (precision lower bound, precision upper bound) )\n",
    "    '''\n",
    "\n",
    "    labeled_pairs.drop_duplicates(inplace=True)\n",
    "    labeled_pairs.columns = ['id1', 'id2', 'label']\n",
    "    reduced_cands.columns = ['id1', 'id2']\n",
    "    reduced_cand_set = set(zip(reduced_cands.id1, reduced_cands.id2))\n",
    "    predicted_matches = set(zip(predicted_matches.id1, predicted_matches.id2))\n",
    "    \n",
    "    # estimate the recall\n",
    "    # number of positives in the labeled sample\n",
    "    actual_pos = float(labeled_pairs.label.sum())\n",
    "    # the maximum number of postives in the candidate set\n",
    "    max_actual_pos = float(actual_pos + len(reduced_cand_set) - len(labeled_pairs))\n",
    "    \n",
    "    # true positives in the labeled sample\n",
    "    true_pos = float(labeled_pairs.apply(lambda x : (x['id1'], x['id2']) in predicted_matches and x['label'], axis=1).sum())\n",
    "    #estimated recall\n",
    "    recall = float(true_pos / actual_pos)\n",
    "\n",
    "    recall_error = Z * sqrt( ((recall * (1 - recall)) / (actual_pos)) * ((max_actual_pos - actual_pos) / (max_actual_pos - 1)) )\n",
    "\n",
    "\n",
    "    # estimate Precision\n",
    "    labeled_set  = set(zip(labeled_pairs.id1, labeled_pairs.id2))\n",
    "    predicted_pos = float(len(labeled_set & predicted_matches))\n",
    "    \n",
    "    predicted_pos_in_reduced_cand_set = float(len(reduced_cand_set & predicted_matches))\n",
    "    \n",
    "    alpha =  predicted_pos_in_reduced_cand_set / len(predicted_matches)\n",
    "    precision = alpha * (true_pos / predicted_pos)\n",
    "    \n",
    "    precision_error = alpha * Z * sqrt( ((precision * (1 - precision)) / predicted_pos) * (float((len(predicted_matches) - predicted_pos)) / (len(predicted_matches)  - 1)) )\n",
    "\n",
    "    return ((recall - recall_error, recall + recall_error),\n",
    "            (precision - precision_error, precision + precision_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"id1\":H[\"A_id\"],\"id2\":H[\"B_id\"]}\n",
    "label_pairs = pd.DataFrame(data = d)\n",
    "label = z[\"label\"].apply(bool)## transfer 0 and 1 to TRUE and FALSE\n",
    "label_pairs[\"label\"] = label\n",
    "labeled_pairs = label_pairs\n",
    "label_pairs = label_pairs.reset_index(drop=True)\n",
    "print(estimate_PR(labeled_pairs, dfcc, dfp))\n",
    "## The final consequence is ((0.899774426900109, 0.9870180259300797), (0.9507454786427749, 1.0051845278381064))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
