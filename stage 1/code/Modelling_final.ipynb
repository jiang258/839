{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = pd.read_json('dict_train.json', orient = \"records\")\n",
    "test_origin = pd.read_json('dict_test.json', orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_origin[train_origin[\"y\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_origin[test_origin[\"y\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "887+453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get1(x):\n",
    "    if x[\"before\"] in honorifics:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get2(x):\n",
    "    if x[\"sample\"].isupper() == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get3(x):\n",
    "    if x[\"comma_before\"] == 1 and x[\"comma_after\"] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get4(x):\n",
    "    if x[\"before\"] in [\"a\",\"an\",\"the\",\"The\"]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get5(x):\n",
    "    if x[\"before\"] in adjlist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get6(x):\n",
    "    if x[\"after\"] in adjlist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get7(x):\n",
    "    if x[\"before\"] in namelist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get8(x):\n",
    "    if x[\"after\"] in tag or x[\"before\"] in tag:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get9(x):\n",
    "    if x[\"after\"] == \"*\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get10(x):\n",
    "    if x['after'] in afterlist or x['before'] in afterlist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get11(x):\n",
    "    if x[\"after\"] in ['in','by','of','at',\"with\",'to',\"for\",\"from\"] or x[\"before\"] in ['in','by','of','at',\"with\",'to',\"for\",\"from\"] :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get12(x):\n",
    "    if x['after'][-2:] ==\"ed\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get13(x):\n",
    "    if x['before'][-2:] ==\"ed\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get14(x):\n",
    "    return len(x['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get15(x):\n",
    "    if x['sample'][0].isupper() == True:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get16(x):\n",
    "    if x['after'] == \"s\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get17(x):\n",
    "    if x[\"before\"] == \"*\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get18(x):\n",
    "    if x['sample'][-2:] ==\"an\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get19(x):\n",
    "    if x[\"sample\"] in honorifics or x[\"sample\"] in common:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get20(x):\n",
    "    if x[\"after\"] in[\"a\",\"an\",\"the\",\"The\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "afterlist = ['who','and',\"is\",\"has\",\"was\",\"were\",\"had\",\"sat\",\"have\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjlist = [\"poor\",\"cute\",\"old\",\"dear\",\"little\",\"young\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\"siter\",\"brother\",\"daughter\",\"son\",\"aunt\",\"uncle\",\"boy\",\"girl\",\"wife\",\"husband\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "honorifics = [\"Mater\",\"Mr\",\"Miss\",\"Mrs\",\"Ms\",\"Sir\",\"Mistress\",\"Madam\",\"Lord\",\"Dr\",\"Professor\",\"professor\",\"Principal\",\"President\",\"Director\",\"you\",\"lady\",\"Lady\",\n",
    "             \"Senator\",\"Captain\",\"General\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = [\"Father\",\"Mother\",\"Grandfather\",\"Grandmother\",\"I\",\"He\",\"She\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = [\"said\",\"named\",\"called\",\"asked\",\"became\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = train_origin.apply(get1,axis = 1)\n",
    "x2 = train_origin.apply(get2,axis = 1)\n",
    "x3 = train_origin.apply(get3,axis = 1)\n",
    "x4 = train_origin.apply(get4,axis = 1)\n",
    "x5 = train_origin.apply(get5,axis = 1)\n",
    "x6 = train_origin.apply(get6,axis = 1)\n",
    "x7 = train_origin.apply(get7,axis = 1)\n",
    "x8 = train_origin.apply(get8,axis = 1)\n",
    "x9 = train_origin.apply(get9,axis = 1)\n",
    "x10 = train_origin.apply(get10,axis = 1)\n",
    "x11 = train_origin.apply(get11,axis = 1)\n",
    "x12 = train_origin.apply(get12,axis = 1)\n",
    "x13 = train_origin.apply(get13,axis = 1)\n",
    "x14 = train_origin.apply(get14,axis = 1)\n",
    "x15 = train_origin.apply(get15,axis = 1)\n",
    "x16 = train_origin.apply(get16,axis = 1)\n",
    "x17 = train_origin.apply(get17,axis = 1)\n",
    "x18 = train_origin.apply(get18,axis = 1)\n",
    "x19 = train_origin.apply(get19,axis = 1)\n",
    "x20 = train_origin.apply(get20,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = test_origin.apply(get1,axis = 1)\n",
    "b2 = test_origin.apply(get2,axis = 1)\n",
    "b3 = test_origin.apply(get3,axis = 1)\n",
    "b4 = test_origin.apply(get4,axis = 1)\n",
    "b5 = test_origin.apply(get5,axis = 1)\n",
    "b6 = test_origin.apply(get6,axis = 1)\n",
    "b7 = test_origin.apply(get7,axis = 1)\n",
    "b8 = test_origin.apply(get8,axis = 1)\n",
    "b9 = test_origin.apply(get9,axis = 1)\n",
    "b10 = test_origin.apply(get10,axis = 1)\n",
    "b11 = test_origin.apply(get11,axis = 1)\n",
    "b12 = test_origin.apply(get12,axis = 1)\n",
    "b13 = test_origin.apply(get13,axis = 1)\n",
    "b14 = test_origin.apply(get14,axis = 1)\n",
    "b15 = test_origin.apply(get15,axis = 1)\n",
    "b16 = test_origin.apply(get16,axis = 1)\n",
    "b17 = test_origin.apply(get17,axis = 1)\n",
    "b18 = test_origin.apply(get18,axis = 1)\n",
    "b19 = test_origin.apply(get19,axis = 1)\n",
    "b20 = test_origin.apply(get20,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'X1':x1,'X2':x2,'X3':x3,'X4':x4,'X5':x5, 'X6':x6, 'X7':x7, 'X8':x8,'X9':x9,'X10':x10,'X11':x11,'X12':x12,\"X13\":x13,'X14':x14,'X15':x15,'X16':x16,'X17':x17,\"X18\":x18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'X1':b1,'X2':b2,'X3':b3,'X4':b4,'X5':b5, 'X6':b6, 'X7':b7, 'X8':b8,'X9':b9,'X10':b10,'X11':b11,'X12':b12,'X13':b13,'X14':b14,'X15':b15,'X16':b16,'X17':b17,\"X18\":b18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(d)\n",
    "y = train_origin[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(m)\n",
    "y1 = test_origin[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.87      0.92      0.89      2014\n",
      "   positive       0.79      0.68      0.73       887\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2901\n",
      "\n",
      "Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.87      0.88      0.88      2014\n",
      "   positive       0.73      0.71      0.72       887\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2901\n",
      "\n",
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.94      0.90      2014\n",
      "   positive       0.82      0.64      0.72       887\n",
      "\n",
      "avg / total       0.85      0.85      0.84      2901\n",
      "\n",
      "SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.91      0.88      2014\n",
      "   positive       0.76      0.66      0.70       887\n",
      "\n",
      "avg / total       0.83      0.83      0.83      2901\n",
      "\n",
      "MLP\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.90      0.90      0.90      2014\n",
      "   positive       0.76      0.77      0.77       887\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2901\n",
      "\n",
      "Linear Regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.91      0.90      2014\n",
      "   positive       0.78      0.76      0.77       887\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"Logistic\",\"Decision Tree\", \"Random Forest\",\"SVM\",\"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=15, max_features=2),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    MLPClassifier(alpha=1)\n",
    "    ]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    y_pred1 = cross_val_predict(clf,X,y, cv=5)\n",
    "    print(classification_report(y, y_pred1,target_names = ['negative','positive']))\n",
    "y_linear = cross_val_predict(clf,X,y, cv=5)\n",
    "def trans(x):\n",
    "    if x >0.5 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "y_pred1 = list(map(trans,y_linear))\n",
    "print(\"Linear Regression\")\n",
    "print(classification_report(y, y_pred1,target_names = ['negative','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, We don't seprate the Set I into P and Q. Instead, we use 5-fold CV to see the output, and use the last loop of CV as the split of P and Q. So P and Q are not defined in this part, but they do exists and are included in the procedure of CV.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'X1':x1,'X2':x2,'X3':x3,'X4':x4,'X5':x5, 'X6':x6, 'X7':x7, 'X8':x8,'X9':x9,'X10':x10,'X11':x11,'X12':x12,\"X13\":x13,'X14':x14,'X15':x15,'X16':x16,'X17':x17,\"X18\":x18,\"X19\":x19,\"X20\":x20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'X1':b1,'X2':b2,'X3':b3,'X4':b4,'X5':b5, 'X6':b6, 'X7':b7, 'X8':b8,'X9':b9,'X10':b10,'X11':b11,'X12':b12,'X13':b13,'X14':b14,'X15':b15,'X16':b16,'X17':b17,\"X18\":b18,\"X19\":b19,\"X20\":b20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(d)\n",
    "y = train_origin[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(m)\n",
    "y1 = test_origin[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.87      0.92      0.90      2014\n",
      "   positive       0.79      0.69      0.74       887\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2901\n",
      "\n",
      "Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.95      0.88      2014\n",
      "   positive       0.82      0.54      0.65       887\n",
      "\n",
      "avg / total       0.82      0.82      0.81      2901\n",
      "\n",
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.96      0.89      2014\n",
      "   positive       0.86      0.52      0.65       887\n",
      "\n",
      "avg / total       0.83      0.83      0.81      2901\n",
      "\n",
      "SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.91      0.88      2014\n",
      "   positive       0.76      0.68      0.72       887\n",
      "\n",
      "avg / total       0.83      0.84      0.83      2901\n",
      "\n",
      "MLP\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.92      0.90      2014\n",
      "   positive       0.80      0.71      0.75       887\n",
      "\n",
      "avg / total       0.85      0.86      0.85      2901\n",
      "\n",
      "Linear Regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.90      0.89      2014\n",
      "   positive       0.77      0.72      0.74       887\n",
      "\n",
      "avg / total       0.85      0.85      0.85      2901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"Logistic\",\"Decision Tree\", \"Random Forest\",\"SVM\",\"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(max_depth=10,class_weight = {0:6,1:3}),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=15, max_features=2,class_weight = {0:6,1:3}),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    MLPClassifier(alpha = 0.1,random_state = 99,hidden_layer_sizes=(100,80,80))\n",
    "    \n",
    "    ]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    y_pred1 = cross_val_predict(clf,X,y, cv=5)\n",
    "    print(classification_report(y, y_pred1,target_names = ['negative','positive']))\n",
    "y_linear = cross_val_predict(LinearRegression(),X,y, cv=5)\n",
    "def trans(x):\n",
    "    if x > 0.45 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "y_pred1 = list(map(trans,y_linear))\n",
    "print(\"Linear Regression\")\n",
    "print(classification_report(y, y_pred1,target_names = ['negative','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we take a look at the wrong samples, there are multiple outputs, but we just change the variable name each time on the code below, so you may only see one output. You are also welcome to change \"sample\" below into \"before\" or \"after\" to see other things, and you can change \"-1\" to \"1\" to see what is wrongly predicted to be not name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = cross_val_predict(MLPClassifier(alpha = 1,random_state = 99,hidden_layer_sizes=(100,80,80)),X,y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.DataFrame({\"y\":y,\"yp\":y_pred1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English                7\n",
       "Tuesday                4\n",
       "States                 4\n",
       "Excellency             3\n",
       "There                  3\n",
       "Fingerbone             2\n",
       "January                2\n",
       "Society                2\n",
       "Christmas              2\n",
       "Grandmother            2\n",
       "Suddenly               2\n",
       "America                2\n",
       "That                   2\n",
       "Kolokolny Lane         2\n",
       "Company                2\n",
       "Shchupkin              1\n",
       "Prejudice              1\n",
       "Sesame                 1\n",
       "Phil Kearney           1\n",
       "Malkin Tower           1\n",
       "Geneve                 1\n",
       "Washington State       1\n",
       "Byron                  1\n",
       "Springfield            1\n",
       "Coney Island           1\n",
       "Merchant               1\n",
       "Alarm                  1\n",
       "Department             1\n",
       "African                1\n",
       "Station                1\n",
       "                      ..\n",
       "Zoological Society     1\n",
       "Whatever               1\n",
       "Complaint              1\n",
       "Sewing Society         1\n",
       "Warwickshire           1\n",
       "Old World              1\n",
       "Australia              1\n",
       "London                 1\n",
       "Those                  1\n",
       "Someone                1\n",
       "Le Fanu                1\n",
       "Russian                1\n",
       "For God                1\n",
       "Something              1\n",
       "Infantry               1\n",
       "Thin                   1\n",
       "England                1\n",
       "Fort Phil Kearney      1\n",
       "Darkness               1\n",
       "Netherfield            1\n",
       "Enfield                1\n",
       "Housekeeping           1\n",
       "The Golden Notebook    1\n",
       "Spring                 1\n",
       "What                   1\n",
       "Winesburg              1\n",
       "Darwin                 1\n",
       "Virginian              1\n",
       "Equally                1\n",
       "Sixth Avenue           1\n",
       "Name: sample, Length: 169, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_origin[D[\"y\"] - D[\"yp\"] == -1][\"sample\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.85      0.93      0.89      1033\n",
      "   positive       0.81      0.63      0.71       453\n",
      "\n",
      "avg / total       0.84      0.84      0.84      1486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = MLPClassifier(alpha = 1,random_state = 99,hidden_layer_sizes=(100,80,80))\n",
    "model = classifier.fit(X, y)\n",
    "y_p = model.predict(X1)\n",
    "print(\"MLP\")\n",
    "print(classification_report(y1, y_p, target_names = ['negative','positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
